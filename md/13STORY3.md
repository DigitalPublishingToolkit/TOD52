---
Pr-id: MoneyLab
P-id: INC Reader
A-id: 10
Type: article
Book-type: anthology
Anthology item: article
Item-id: unique no.
Article-title: title of the article
Article-status: accepted
Author: name(s) of author(s)
Author-email:   corresponding address
Author-bio:  about the author
Abstract:   short description of the article (100 words)
Keywords:   50 keywords for search and indexing
Rights: CC BY-NC 4.0
...


# STORY 3. Resistance storytelling: Anti-Surveillance campaign in Recife, Brazil

### Kainen Bell

In this essay, I will share recent examples of how Brazilian communities
and activists have resisted digital surveillance, specifically Facial
Recognition, and how these technologies embody data colonialism.
Currently, I am a doctoral student in Information Sciences at the
University of Illinois at Urbana Champaign, researching how
Afro-Brazilian communities resist digital surveillance technologies, and
how to use my identities as an African American and Researcher, to
support their grassroots movements. My interest in this topic sparked
from a personal experience traveling to Recife, Brazil (where I was
living at the time) and being required to use facial recognition to
confirm my identity before boarding the flight. It worried me due to
seeing recent stories of Black individuals being misidentified, and I
was concerned it could happen to me as well.

![Image 1: “No Camera in my Face!” Campaign website, describing that the
City of Recife wants to install 108 facial recognition cameras around
the city and the need to prevent its acquisition, translated to English
via google translate.
(https://www.semcameranaminhacara.meurecife.org](imgs/story3Image1.png)

<br/>

Surprisingly, one year later while scrolling on Instagram, I learned
about a local Brazilian anti-surveillance campaign titled ‘No Camera in
my Face!’.[^13STORY3_1] The campaign was founded in 2021 by grassroots organizers
and human rights groups, to prevent the initialization of over 100
facial recognition cameras throughout Recife. Their campaign included a
website describing the facial recognition initiative and its potential
to replicate racism, transphobia, target activists, and violate the
personal privacy rights of citizens. In May 2021, Recife’s Mayor, João
Henrique Campos, proposed an initiative to install 108 digital clocks
that would display the time, business advertisements, share free public
Wi-Fi, but also include monitoring cameras with facial recognition
capabilities.[^13STORY3_2] Justifications for the cameras were to assist with
traffic management and preserving the security of public property.[^13STORY3_3]
An open call was created to invite national and international technology
companies to bid for the contract to install and maintain the system for
20 years. The contracted company would also be permitted to use the
advertising services of the digital clocks and have access to all data
collected. This project is the first of a series of public-private
partnership infrastructure initiatives that the mayor intends to
implement before his term ends. This initiative exemplifies data
colonialism because of the unbalanced power of city municipalities to
implement surveillance tools that have capabilities to monitor and track
its citizens against their will, and because of the technology company’s
profit driven interests and ability to extract data from the population
without their knowledge.

In response, twenty-five grassroots and human rights organizations
signed an open letter to the mayor requesting the cameras be removed
from the project.[^13STORY3_4] Their concerns included poor data management
protocols, a lack of transparency of the private company’s access to or
use of the data collected, and the possibility for racial and gender
discrimination. The organizations soon after created the ‘No Camera in
my Face!’ campaign. Campaign leaders raised awareness through public
interviews critiquing the mayor’s initiative. For example, Raquel
Saraiva, President of the Research Institute on Law and Technology of
Recife (IP.rec) warned of the low accuracies of the facial recognition
systems created in the Global North but applied to Brazil. She says:
*‘*The import would be from the Global North, which has a completely
different social composition from ours. With the representativeness
different from that of the databases, the algorithm becomes even more
poorly trained*’*.[^13STORY3_5] Her words also painted a picture of why this
project represents data colonialism.

![Image 2: “No Camera in my Face!” Campaign website, asks the question
“Do you know what are the risks we currently take with the
implementation of a Facial Recognition System in the City of Recife?”
and lists risks of Racism, Transphobia, Persecution of activists and
social movements, and Data Protections and Privacy, translated to
English via google translate.
(https://www.semcameranaminhacara.meurecife.org](imgs/story3Image2.png)

<br/>

A common narrative used to convince communities to buy into using facial
recognition cameras are that they will reduce crimes, improve public
safety, and because technology is more accurate and unbiased compared to
humans. However, studies have proven that even the leading facial
recognition systems created by global technology companies like
Microsoft, Amazon, and IBM, have demonstrated high inaccuracies when
used on racial minorities, especially women with darker skin tones.[^13STORY3_6]
Misidentifications often occur when the database of images used to test
and create the systems are not diverse or inclusive of people with
different gender identities or races. In addition, technologies often
replicate discrimination and inequalities that already exist.[^13STORY3_7] For
example, when used by police, who historically have oppressed
marginalized groups like black, low-income, and transgender populations,
it creates huge risks. This is especially true in Brazil which has the
third highest incarceration rate in the world (67% imprisoned are black
or brown people), the most African Descendants outside the African
continent, and research proving that police overuse these technologies
on Black-Brazilians.[^13STORY3_8] Black Brazilians are also 2.3 times more likely
to be killed by police than white Brazilians[^13STORY3_9] and it was reported
that in 2019, 151 people were arrested in Rio de Janeiro and Bahia using
Facial Recognition, and 90.5% were Afro-Brazilians.[^13STORY3_10]

Misidentifications from police have already occurred in Brazil,
including the 2019 Carnaval event in Rio de Janeiro, where a woman was
falsely identified as a convicted murderer.[^13STORY3_11] She was without
documentation and unable to prove her identity, but fortunately the
charges were dropped after being correctly identified at the police
station. Recently, in Rio De Janeiro, it was also reported that a black
educator man named Danilo Felix was misidentified and arrested on two
separate occasions due to photographic recognition systems.[^13STORY3_12] The
first incident occurred in 2020 when he was mistakenly charged with
theft due to a Facebook image used by a police database that identified
him as a crime suspect. He was acquitted after the assault victim proved
his innocence, however his image remained in the police database, and
this year (April 2023) was falsely arrested for another crime.

Transgender communities are also at risk from these technologies. Coding
Rights, a Feminist Digital Human Rights organization in Brazil,
conducted a study on the impacts that facial recognition technologies
have on transgender communities. They found that 90.5% of transgender
individuals believed that facial recognition could operate from a
transphobic perspective.[^13STORY3_13] These findings resonate with the
experiences of Sasha Costanza-Chock in her book, Justice Design, when
describing her experiences as a transgender woman entering the full body
scanners in airports and being exposed to vulnerable situations by the
binary (male vs female) algorithms.[^13STORY3_14] Transgender communities are
already vulnerable to targeting and for 14 consecutive years Brazil has
had the highest violence and murder rate of transgender populations in
Latin America.[^13STORY3_15] Similar to colonial power, surveillance technologies
operate to make white cis-gender individuals the standard and invisible,
while racial minorities and non-gender conforming individuals are
hyper-visible and constantly surveilled.

Due to the demands of the campaign organizers, there were two public
hearings with the city council to share concerns and in March 2022 the
Public Ministry of Pernambuco opened a civil inquiry to investigate the
possibility of racial discrimination.[^13STORY3_16] However, despite the concerns
raised, in June of 2022 the project was contracted to Eletromidia
(Brazil’s largest home media and advertising company) for \$102 million
Brazilian Reais (\$19.3 Million USD).[^13STORY3_17] The mayor said the company
would only build and maintain the project, instead of having the power
to initiate the cameras or collect the data. In addition, he said the
cameras would not be activated until there was a regulation policy made.

![Image 3: “No Camera in my Face!” Campaign website, Titled “Who makes
the campaign happen” and lists the collaborating partners including
IP.rec, ANEPE, LAVITS, CDPH, and Rede Justiça Criminal, NATRAPE, and AB
Pernambuco, translated to English via google translate.
(https://www.semcameranaminhacara.meurecife.org](imgs/story3Image3.png)

<br/>

This was difficult news for the campaign, but it has not stopped them.
An organizer mentioned that their efforts slowed afterwards due to
shifting attention on the 2022 Presidential elections in October.
However, they are currently focused on increasing public awareness
through community workshops in Recife. Digital rights campaigns have
typically been led by middle class folks and academics, instead of the
vulnerable communities that are directly impacted.[^13STORY3_18] By grounding
their work in the community, understanding their needs, and showing how
these facial recognition projects can impact their lives, it can
strengthen the resistance movement and create more impactful solutions
moving forward.

Their resistance campaign relates to a national movement in Brazil to
completely ban the use of Facial Recognition Technology for security in
public spaces, ‘Get my Face out of Your Sight!’ (Tire Meu Rosto Da Sua
Mira). It was launched in May 2022 by thirty civil society and digital
rights organizations from an open letter calling for the banning of
Facial Recognition Technologies.[^13STORY3_19] Their campaign includes a website
and provides toolkits for community groups to create anti-surveillance
campaigns in their areas, as well as maps of anti-surveillance
legislation in Brazil. Horrara Silva, a consultant for the campaign,
recently mentioned to me their efforts to stop a facial recognition
initiative proposed by the city of São Paulo named Smart Sampa. The
project intends to install 20,000 facial recognition cameras around
schools, health institutions, parks, and other heavily populated
areas.[^13STORY3_20] In partnership with the Public Defender’s Office, several
human rights organizations have entered a lawsuit to sue the city and
stop the bidding process.

As an ally to anti-surveillance projects in Brazil, I encourage everyone
to read and sign their open letter to ban the use of these
technologies.[^13STORY3_21] I also encourage you to read the work of Coding
Rights,[^13STORY3_22] LAVITS,[^13STORY3_23] and the organizations within the ‘No Camera in
my Face!’ campaign. These resistance movements are instrumental to
stopping data colonialism and preventing the installation of
surveillance technologies that discriminate and criminalize minoritized
populations such as Black, low-income, and transgender communities. We
must continue to resist, protest, and never give up the fight!

[^13STORY3_1]: Sem Câmera na Minha Cara.
    https://www.semcameranaminhacara.meurecife.org.br

[^13STORY3_2]: Augusto Tenório, ‘Organizações pedem que PCR abandone projeto de
    relógios com reconhecimento facial’, Universo Online, 23 Novembro
    2021.
    https://jc.ne10.uol.com.br/blogs/jamildo/2021/11/14354363-organizacoes-pedem-que-pcr-abandone-projeto-de-relogios-com-reconhecimento-facial.html

[^13STORY3_3]: Secretaria de Desenvolvimento Econômico, Ciência, Tecnologia e
    Inovação Institucional, ‘Prefeitura recebe proposta de R\$ 100
    milhões para a concessão dos novos relógios eletrônicos digitais’,
    Prefeitura Do Recife, 22 Junho 2022.
    https://www2.recife.pe.gov.br/noticias/22/06/2022/prefeitura-recebe-proposta-de-r-100-milhoes-para-concessao-dos-novos-relogios

[^13STORY3_4]: Maria Carolina Santos, ‘Os riscos das 108 câmeras de
    reconhecimento facial que a prefeitura quer espalhar pelo Recife’,
    Marco Zero, 22 Novembro 2021.
    https://marcozero.org/os-riscos-das-108-cameras-de-reconhecimento-facial-que-a-prefeitura-quer-espalhar-pelo-recife/

[^13STORY3_5]: Maria Lígia Barros, ‘Câmeras com reconhecimento facial no Recife
    podem agravar racismo e ameaçar direitos’, Brasil de Fato, 21 Março
    2022.
    https://www.brasildefatope.com.br/2022/03/21/cameras-com-reconhecimento-facial-no-recife-podem-agravar-racismo-e-ameacar-direitos

[^13STORY3_6]: Buolamwini and Gebru, ‘Gender Shades: Intersectional Accuracy
    Disparities in Commercial Gender Classification’.

[^13STORY3_7]: Simone, Dark Matters: On the Surveillance of Blackness.

[^13STORY3_8]: Barros, ‘Câmeras com reconhecimento facial no Recife podem agravar
    racismo e ameaçar direitos’.

[^13STORY3_9]: David Nemer, Technology of the Oppressed : Inequity and the
    Digital Mundane in Favelas of Brazil, The MIT Press, 2022.

[^13STORY3_10]: Pablo Nunes, ‘Exclusivo: levantamento revela que 90,5% dos presos
    por monitoramento facial no Brasil são negros’, Intercept Brasil, 21
    Novembro 2019.
    https://www.intercept.com.br/2019/11/21/presos-monitoramento-facial-brasil-negros/

[^13STORY3_11]: Edmund Ruge, ‘Brazil’s Biggest Metro Could Get Facial Recognition
    Cameras That Reinforce Racist Policing’, Vice, 2 March 2021.
    https://www.vice.com/en/article/5dp8wq/brazils-biggest-metro-could-get-facial-recognition-cameras-that-reinforce-racist-policing%E2%80%AF%E2%80%AF%E2%80%AF

[^13STORY3_12]: NINJA, ‘Pela segunda vez, jovem negro inocente vira réu após
    reconhecimento por foto’, Mídia NINJA, 12 Abril 2023.
    https://midianinja.org/news/pela-segunda-vez-jovem-negro-inocente-vira-reu-por-causa-de-reconhecimento-por-foto/

[^13STORY3_13]: Mariah Rafaela Silva and Joanna Varon, ‘Threats in the Usage of
    Facial Recognition Technologies for Authenticating Transgender
    Identities’, Privacy International, 30 March 2021.
    http://privacyinternational.org/news-analysis/4474/threats-usage-facial-recognition-technologies-authenticating-transgender

[^13STORY3_14]: Sasha Costanza-Chock, Design Justice: Community-Led Practices to
    Build the Worlds We Need, MIT Press, 2020.

[^13STORY3_15]: Ester Pinheiro, ‘Brazil continues to be the country with the
    largest number of trans people killed’, Brasil de Fato, 23 Janeiro
    2022.
    https://www.brasildefato.com.br/2022/01/23/brazil-continues-to-be-the-country-with-the-largest-number-of-trans-people-killed

[^13STORY3_16]: Barros, ‘Câmeras com reconhecimento facial no Recife podem
    agravar racismo e ameaçar direitos’.

[^13STORY3_17]: Secretaria de Desenvolvimento Econômico, Ciência, Tecnologia e
    Inovação Institucional, ‘Prefeitura recebe proposta de R\$ 100
    milhões para a concessão dos novos relógios eletrônicos digitais’.

[^13STORY3_18]: Nemer, Technology of the Oppressed : Inequity and the Digital
    Mundane in Favelas of Brazil.

[^13STORY3_19]: Civil society (56 organisations and 419 individuals), ‘Open
    Letter to Ban the Use of Digital Facial Recognition Technologies in
    Public Security’, Tire Meu Rosto Da Sua Mira, 8 March 2022.
    https://tiremeurostodasuamira.org.br/en/open-letter/

[^13STORY3_20]: Carlos Petrocilo, ‘Defensoria Pública vai à Justiça contra
    programa de reconhecimento facial em SP’, Folha de S. Paulo, 24 Maio
    2023.
    https://www1.folha.uol.com.br/cotidiano/2023/05/defensoria-publica-vai-a-justica-contra-programa-de-reconhecimento-facial-em-sp.shtml

[^13STORY3_21]: Tire Meu Rosto Da Sua Mira.
    https://tiremeurostodasuamira.org.br/en/home-eng/

[^13STORY3_22]: Coding Rights. Hacking the Patriarchy.
    https://codingrights.org/en/

[^13STORY3_23]: Lavits - Rede Latino-Americana de Estudos Sobre Vigilância,
    Tecnologia e Sociedade. https://lavits.org/en/lavits/
